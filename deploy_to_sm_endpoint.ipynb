{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "795e072f-81ce-4e93-80f6-956de68f8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "515d2aeb-beae-4d30-9cdf-6cc2d10a0b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filePath = 'model/model.tar.gz'\n",
    "\n",
    "if os.path.exists(filePath):\n",
    "    os.remove(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bde95ec2-4b0d-4b88-96dd-8e855c8aac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"flan-ul2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a5625164-426a-49a3-a45d-e04ed2ff5df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/deploy-flan-ul2-sagemaker/model\n"
     ]
    }
   ],
   "source": [
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1db29098-cf7d-42ce-82a0-d793f9824b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/requirements.txt\n",
      "code/.ipynb_checkpoints/\n",
      "code/.ipynb_checkpoints/requirements-checkpoint.txt\n",
      "code/.ipynb_checkpoints/inference-checkpoint.py\n",
      "code/inference.py\n"
     ]
    }
   ],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e957c033-8c14-45e1-8be2-0c1c5742117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_location = f\"s3://{sess.default_bucket()}/{model_name}/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3968fe8-516e-4bbb-b58c-3e98755db96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5917fdfd-e1d4-4597-a5a5-e18f027e179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/deploy-flan-ul2-sagemaker\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ecebdb26-381f-4288-930a-8f6e7b7a7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data=s3_location,\n",
    "    role=role,\n",
    "    transformers_version=\"4.17\",\n",
    "    pytorch_version=\"1.10\",\n",
    "    py_version='py38',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52512bee-4f75-4309-8d7c-71b35e8f2021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "endpoint_name = name_from_base(model_name)\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.4xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b104d57-e828-400a-9f13-4e671ebb1568",
   "metadata": {},
   "source": [
    "!!!NOTE: Even after the endpoint has been deployed, we still need to wait 1-2 minutes before we can start using it. That's because the model is downloading from the HF Model Hub and due to its size it won't be quite finished when the endpoint is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b68143a-b021-4f17-9163-9d1acfda52c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flan-ul2-2023-03-11-13-15-42-386'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a558e546-eb08-4e2d-a2ba-d9e19c4e0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Answer the following question by reasoning step by step.\n",
    "The cafeteria had 23 apples. If they used 20 for lunch, and bought 6 more, how many apples do they have now?\"\"\"                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ac88d44-99e9-4584-b63f-a62334e01f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They have 23 - 20 = 3 apples left after using some for lunch. They now have 3 + 6 = 9 apples. Therefore, the final answer is 9.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"inputs\": prompt,\n",
    "    \"min_length\": 20,\n",
    "    \"max_length\": 50,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.6,\n",
    "}\n",
    "\n",
    "res = predictor.predict(data=data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c67c87-8672-4f21-9f5d-d28b9121eb32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
